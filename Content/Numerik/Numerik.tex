\section{Numerik}
\subsection{Diskretisierung}
\subsubsection{1.Ableitung}

$$g'\approx \frac{g(x+\Delta x)-g(x)}{\Delta x} \qquad\qquad \text{oder} \qquad\qquad g'\approx \frac{g(x+\Delta x)-g(x-\Delta x)}{2\Delta x}\qquad \text{(Bessere Qualität)}$$
\subsubsection{2.Ableitung}

$g''\approx \frac{g(x+\Delta x)-2 g(x) + g(x- \Delta x)}{\Delta x^2}$

\subsection{FDM}
\textbf{TIPP:} Bei Anfangsbedingungen ungleich Null das Gleichungssystem selber von Hand herleiten, reduziert die Chance auf Fehler.
\subsubsection{Grundgleichung: $-u''(x)=f(x)$}
$ A^{(n)} \tilde{u}^{(n)} =f^{(n)}   $\\
$A^{(n)}= \frac{1}{\Delta x^2} tridiag {n-1} (-1,2,-1) = \frac{1}{\Delta x^2}
  \begin{bmatrix}
             2& -1 & 0 & \ldots \\
             -1& 2 & -1 & \ldots \\
              0& -1 & 2 & \ldots \\
              0& 0 & -1 & \ldots \\
             \ldots 
           \end{bmatrix} (eine (n-1)x(n-1)-Matrix)$\\ 
Randwert: $\tilde{u}(0)= a; \tilde{u}(n)=b $
$A^{(n)}=\tilde{u}^{(n)} =\begin{bmatrix}
             f(0) + \tilde{u}(0) \\
             f(1) \\
             \vdots  \\
             f(n) + \tilde{u}(n)
           \end{bmatrix} $\\
\subsubsection{Grundgleichung: $T''(x) + h (T_A -T(x)) = 0)$}
$-T'' + h T(x) = h T_A$\\
$A^{(n)}= \frac{1}{\Delta x^2} tridiag {n-1}
(2+h\Delta x^2 ) = \frac{1}{\Delta x^2}
  \begin{bmatrix}
             2+h\Delta x^2& -1 & 0 & \ldots \\
             -1& 2+h\Delta x^2 & -1 & \ldots \\
              0& -1 & 2+h\Delta x^2 & \ldots \\
              0& 0 & -1 & \ldots \\
             \ldots 
           \end{bmatrix} $\\       
           
           
           
\subsection{Konvergenz}
Ein Modell ist konvergent wenn bei $n\leftarrow\infty$ die Schätzung $\tilde{u}$ und $u$ übereinstimmt.\\

$\boxed{||v||_{\Delta x}=\sqrt{\Delta x (v_1^2+v_2^2 + \ldots v_{n-1}^2)}= \sqrt{\Delta
x}||v||}$\\
Es konvertiert wenn: $\lim\limits_{n\to \infty
}||\tilde{u}^{(n)}-u^{(n)}||=0=\sqrt{\frac{1}{n}}||\tilde{u}^{(n)}-u^{(n)}=\sqrt{\frac{1}{n}}\sqrt{(\tilde{u}_1)-u_1)^2
+ \ldots + \tilde{u}_{n-1}-u_{n-1}}$\\

\subsection{Konsistenz}
Ein Modell ist nicht konsistent wenn das Modell durch Vereinfachung nicht mehr mit der Realität übereinstimmt.

Globaler Konsistenzfehler: $\boxed{||r^{(n)}||_{1/n}\leq \frac 1{12}\max\limits_{\xi\in[0,1]}|f''(\xi)|\cdot \Delta x^2}$

\subsubsection{Residuum}
Exakt: $A^{(n)}\cdot \tilde{u}^{(n)}-f^{(n)}=0$\\
Residuum: $A^{(n)}\cdot (u^{(n)}-\tilde{u}^{(n)})=r^{(n)}$

Eine Approximationsverfahren ist Konsistent, wenn $\boxed{\lim\limits_{n\rightarrow \infty}||r^{(n)}||_{1/n}=0}$ gilt.\\

Konsistenz ist eine notwendige, aber nicht hinreichende Bedingung für die Konvergenz eines Verfahrens.

\subsubsection{Taylor}
$g(x)= \sum\limits_{k=0}^n\frac{1}{k!} g^{(n)}(x_0)(x-x_0)^k +
\frac{1}{(n+1)!}g^{(n+1)}(\xi)(x-x_0)^{n+1}$ = Taylor
Approximationspolynom  + Lagronesche Restglied ($\xi$ ist unabhängig von $x,
x_0$)



\subsubsection{Vorwärt/Rückwärtsdifferenz}
$g'(x) - \frac{g(x+\Delta x) + g(x)}{\Delta x}= O(\Delta x) = 
\frac{g''(\xi_1)}{2}\Delta x^2 \Rightarrow 1.Ordnung$


\subsubsection{Zentraldifferenz}
$g'(x) - \frac{g(x+\Delta x) + g(x-\Delta x)}{2\Delta x}= O(\Delta x^2) = 
\frac{g''(\xi_1)}{2}\Delta x^2 \Rightarrow 2.Ordnung$ 



\subsubsection{2.Ableitung}
$g''(x) - \frac{g(x+\Delta x) -2 g(x)+ g(x-\Delta x)}{2\Delta x}= O(\Delta x^2)
= \frac{g''(\xi_1)}{2}\Delta x^2 \Rightarrow 1.Ordnung$

\subsection{Stabilität}
Die Stabilität einer Matrize kann über deren Norm $||A||_*$ bestimmt werden.\\

Es gilt: $||A||_*=\max\limits_{||X||_*=1}||A\cdot x||_*$\qquad$||A\cdot x||_*\leq||A||~||x||_*$\\

Ein Approximationsverfahren ist stabil wenn, wenn unabhängig von der konstante $C$ gilt:
$\boxed{||{A^{(n)}}^{-1}||\leq C}$\\



Die Bestimmung von $||A||$ ist im Allgemeinen nicht einfach, darum wird $||A||$ oft über den Umweg der Diagonalisierung von A bestimmt.

$y=A\cdot x\qquad\Rightarrow\qquad\tilde{y}=D\cdot\tilde{x}$\qquad mit\qquad $D=\begin{bmatrix}\lambda_1&&\\&\ddots&\\&&\lambda_n\end{bmatrix}$\\

Es gilt $TAT^T=D$, wobei T die Transformationsmatrix vom $x$-Koordinatensystem zum $\tilde{x}$-Koordinatensystem darstellt. $T$ ist orthogonal.
Die Diagonalelemente $\lambda_1,\ldots,\lambda_n$ werden auch Eigenwerte genannt.\\

Eine Approximationsformel ist stabil wenn: $\boxed{||A||=\max\limits_{k}|y_k|\leq C}$\\

Eigenwerte bestimmen: $\boxed{\det(A-\lambda I)=0}\qquad \Rightarrow \qquad \lambda_1,\ldots,\lambda_n$\\
Eigenvektoren bestimmen (für jedes $\lambda_i$): $A-\lambda_i I=0\qquad \Rightarrow \qquad v_1,\ldots,v_n$\\

\subsection{FDM für elliptisch PDGL (Poisson: $\Delta u = f$)}
%Dirichletsche Randbedingung ($u(x,y)= f(x,y) \forall (x,y)\epsilon \delta G)$\\

Gleichung:    $-\Delta u(x,y)= f(x,y) $
$\frac{g(x+\Delta x,y ) -2 g(x,y)+ g(x-\Delta x,y)}{2\Delta x} +
\frac{g(x,y+\Delta y) -2 g(x,y)+ g(x,y-\Delta y)}{2\Delta y}$\\

$h=\Delta x = \Delta y \Rightarrow \boxed{\frac 1 {h^2} (\tilde{u}_{j,k+1} +
\tilde{u}_{j+1,k} + \tilde{u}_{j,k-1} + \tilde{u}_{j-1,k} - 4 \tilde{u}_{j,k})
= f_{j, k}}$\\[0.4cm]


$B \tilde{u} = f \Rightarrow B= \begin{bmatrix}
             T& D & 0 & \ldots \\
             D& T & D & \ldots \\
              0& D & T & \ldots \\
              0& 0 & D & \ldots \\
             \ldots 
           \end{bmatrix}$
wobei $T=\begin{bmatrix}
             4& -1 & 0 & \ldots \\
             -1& 4 & -1 & \ldots \\
              0& -1 & 4 & \ldots \\
              0& 0 & -1 & \ldots \\
             \ldots 
           \end{bmatrix}$
und $D=\begin{bmatrix}
             -1& 0& 0 & \ldots \\
             0 & -1 &  & \ldots \\
              0& 0&-1 & \ldots \\
             \ldots 
           \end{bmatrix}$

           
\subsubsection{Irreguläre Gitter (für den Rand)}
\begin{minipage}{5cm}
	\includegraphics[width=5cm]{Content/Numerik/irregulaereGitter.png}

\end{minipage}
\begin{minipage}{14cm}

$\left(\frac{u(x+eh,y)-u(x,y)}{e(e+w)} +\frac{u(x+wh,y)-u(x,y)}{w(e+w)}+\frac{u(x+nh,y)-u(x,y)}{n(n+s)} + \frac{u(x+sh,y)-u(x,y)}{n(n+s)}\right)\frac{2}{h^2}=f(x,y)$\\

oder
\\

$\frac{u(P_E) - u(P)}{e(e+w)} + \frac{u(P_W) - u(P)}{w(e+w)} + \frac{u(P_N) - u(P)}{n(n+s)} + \frac{u(P_S) - u(P)}{s(n+s)} = \frac{h^2}{2} f(x,y)$
\end{minipage}
\subsubsection{Neumann Rand 
%$\partial_n u(x,y) \forall (x,y) \epsilon \partial_n G$
}
\begin{minipage}{8cm}
	\includegraphics[width=8cm]{Content/Numerik/NeumannRand.png}


\end{minipage}
\begin{minipage}{10cm}
In einem Randpunkt P liegen wie in der Abbildung ersichtlich, $P_N$ und $P_S$ auf dem Rand von Omega, $P_W$ liegt ausserhalb von Omega.\\
In P sei die Neumannsche Randbedingung: $\boxed{\partFrac{u}{n}(P)=g(P)}$\\
$u_x(P)=\frac{u(P_E)-u(P_W)}{2h}\quad\Rightarrow\quad u(P_W)=u(P_E)-2h\cdot u_x(P)$\\

$\boxed{\frac{2u(P_E) + u(P_N) +
u(P_S)- 4 u(P) - 2h\cdot u_x(P)}{h^2}}$\\


\textbf{Spiegelmethode}:\\
Wenn $u_x(x,y) = 0$, dann spricht man auch von der Spiegelmethode. Die Punkte $P_W$ und $P_E$ weisen dann die gleiche Wertigkeit auf ($P_W=P_E$).
\end{minipage}


\subsection{FDM für parabolische PDGL}
	Wärmeleitungsgleichung: $\boxed{u_t(x,t)=u_{xx}(x,t)}$\qquad $f(0)=f(1)=0$ \qquad$ \overset{\_}{\Omega}=[0,1]\times [0,\infty]$\\
	
	Randbedingungen: $u(x,0)=f(x) \qquad u(0,t)=u(1,t)=0\qquad x\in(0,1) \qquad t\in[0,\infty)$
\subsubsection{Explizites Verfahren (Richardson-Verfahren)}
$\boxed{\frac{\tilde{u}(x,t+\Delta t) - \tilde{u}(x,t)}{\Delta t} = 
\frac{\tilde{u}(x+\Delta x, t)-2\tilde{u}(x,y) + \tilde{u}( x - \Delta x, t )} {\Delta x^2}} \qquad \Delta x=\frac 1n\qquad \Delta t=\frac r{n^2} \qquad \boxed{r=\frac{\Delta
t}{\Delta x^2}}$\\

\textbf{Idee:} Aus den Positionen k wird k+1 berechnet: $\tilde{u}_{j,k+1} = r \tilde{u}_{j-1,k} + (1-2r)\tilde{u}_{j,k} + r \tilde{u}_{j+1,k}$\\


\begin{itemize}
\item Initialisierung, Randbedingung: $\tilde{u}_{j,0}=f(j/n)$ \qquad $\tilde{u}_{0,k}=\tilde{u}_{n,k}=0$
\item Approximationsmatrize: $C^{(n)}=tridiag_{n-1}(r,1-2r,r)=\begin{bmatrix}
1-2r& r		& 0		& 0 	&\cdots\\
r	& 1-2r  & r		& 0		&\cdots\\
0	& r		& 1-2r 	& r 	&\cdots\\
0	& 0		& r		& 1-2r 	&\cdots\\
\vdots&	\vdots&\vdots&\vdots&\ddots	
\end{bmatrix}$ 
\item Einen Schritt berechnen: $\tilde{u}^{(k+1)}=C^{(n)} \tilde{u}^{(k)}$
\item k-Schritte berechnen: $\tilde{u}^{(k)}=\big\{C^{(n)}\big\}^k \tilde{u}^{(0)}$
\end{itemize}

\textbf{Konvergenzverhalten:} \\

\begin{minipage}{6cm}
\includegraphics[width=6cm]{Content/Numerik/KonvExplizit.png}
\end{minipage}
\hfill
\begin{minipage}{12cm}
Verfahren ist stabil wenn: $||A^{-1}|| < 1 \qquad \Rightarrow\qquad r < \frac{1}{2}$\\

Dies macht es Nötig die Zeitschritte extrem klein zu wählen, darum ist das Verfahren auch nicht wirklich praxistauglich, weil sehr hohe Rechenkapazität nötig sind.\\

Der Grund für das schlechte Konvergenzverhalten kann geometrisch visualisiert werden. In die Berechnung des Wertes im Knoten $P$, werden die Werte aller schwarz eingefärbter Knoten eingehen. Von den Randwerten wird nur die 0-te Stufe berücksichtigt.
\end{minipage}






\subsubsection{Implizites Verfahren}
Im Unterschied zum expliziten Verfahren, das Werte vom vorherigen Zeitpunkt nutzt, wird hier das ein Gleichungssystem global gelöst.\\

$\boxed{\frac{\tilde{u}(x,t) - \tilde{u}(x,t -\Delta t)}{\Delta t} = 
\frac{\tilde{u}(x+\Delta x, t)-2\tilde{u}(x,y) + \tilde{u}( x - \Delta x, t )} {\Delta x^2}}$\\

$ \tilde{u}_{j,k} = r \tilde{u}_{j-1,k+1} + (1+2r)\tilde{u}_{j,k+1} + r \tilde{u}_{j+1,k+1}$

\textbf{Idee:} Die Ableitungen werden mittels Rückwärtsdifferenz berechnet\\


\begin{itemize}
\item Initialisierung, Randbedingung: $\tilde{u}_{j,0}=f(j/n)$ \qquad $\tilde{u}_{0,k}=\tilde{u}_{n,k}=0$
\item Approximationsmatrize: $E^{(n)}=tridiag_{n-1}(-r,1+2r,-r)=\begin{bmatrix}
1+2r& r		& 0		& 0 	&\cdots\\
r	& 1+2r  & r		& 0		&\cdots\\
0	& r		& 1+2r 	& r 	&\cdots\\
0	& 0		& r		& 1+2r 	&\cdots\\
\vdots&	\vdots&\vdots&\vdots&\ddots	
\end{bmatrix}$ 
\item Einen Schritt berechnen: $\tilde{u}^{(k+1)}=\left\{E^{(n)}\right\}^{-1} \tilde{u}^{(k)}$
\item k-Schritte berechnen: $\tilde{u}^{(k)}=\left(\left\{E^{(n)}\right\}^{-1}\right)^k \tilde{u}^{(0)}$
\end{itemize}

\textbf{Vorteil:} Das implizite Verfahren ist immer stabil, unabhängig von der Zeitauflösung $\Delta t$\\
\textbf{Nachteil:} Aufwendige Matrixinversion nötig.

\subsubsection{Crank Nicolson -Verfahren (gemischtes Verfahren)}

Die Idee des Verfahrens von Crank-Nicolson ist es die Approximationen\\

$\boxed{\frac{\tilde{u}(x,t+\Delta t) - \tilde{u}(x,t)}{\Delta t} = 
\frac{\tilde{u}(x+\Delta x, t)-2\tilde{u}(x,y) + \tilde{u}( x - \Delta x, t )} {\Delta x^2}}$\\

und\\

$\boxed{\frac{\tilde{u}(x,t) - \tilde{u}(x,t -\Delta t)}{\Delta t} = 
\frac{\tilde{u}(x+\Delta x, t)-2\tilde{u}(x,y) + \tilde{u}( x - \Delta x, t )} {\Delta x^2}}$\\

zu mitteln. Mit dieser Idee geht das stetige Problem in folgendes diskretes Problem über:

$-r \tilde{u}_{j-1,k+1} + (2+2r)\tilde{u}_{j,k+1} - r \tilde{u}_{j+1,k+1} = r
\tilde{u}_{j-1,k+1} + (2-2r)\tilde{u}_{j,k+1} + r \tilde{u}_{j+1,k+1} $



\begin{itemize}
\item Initialisierung, Randbedingung: $\tilde{u}_{j,0}=f(j/n)$ \qquad $\tilde{u}_{0,k}=\tilde{u}_{n,k}=0$
\item Approximationsmatrizen:\\
$F^{(n)}=E^{(n)}+I=tridiag_{n-1}(-r,2+2r,-r)=\begin{bmatrix}
2+2r& -r	& 0		& 0 	&\cdots\\
-r	& 2+2r  & -r	& 0		&\cdots\\
0	& -r	& 2+2r 	& -r 	&\cdots\\
0	& 0		& -r	& 2+2r 	&\cdots\\
\vdots&	\vdots&\vdots&\vdots&\ddots	
\end{bmatrix}$\\
$G^{(n)}=C^{(n)}+I=tridiag_{n-1}(~r,~2-2r,~r~)=\begin{bmatrix}
2-2r& r		& 0		& 0 	&\cdots\\
r	& 2-2r  & r		& 0		&\cdots\\
0	& r		& 2-2r 	& r 	&\cdots\\
0	& 0		& r		& 2-2r 	&\cdots\\
\vdots&	\vdots&\vdots&\vdots&\ddots	
\end{bmatrix}$ 
\item Einen Schritt berechnen: $\tilde{u}^{(k+1)}=\left\{F^{(n)}\right\}^{-1} \cdot G^{(n)}\cdot \tilde{u}^{(k)}$
\item k-Schritte berechnen: $\tilde{u}^{(k)}=\left(\left\{F^{(n)}\right\}^{-1} \cdot G^{(n)}\right)^{k}\cdot \tilde{u}^{(0)}$
\end{itemize}

\subsection{(FDM für Hyperbolische PDGL)}

$$u_{tt}=u_{xx} = homogen$$
$$u_{tt} -u_{xx}= v(x,t) = inhomogen$$

$$\Longrightarrow u_{j,k+1}=r^2 u_{j-1,k} 2(1-r^2)u_{j,k}+ r^2
u_{j+1,k}-u_{j,k-1}$$
\subsubsection{Anfangsbedingungen}
$$\tilde{u}_{j,0} = f(j\Delta x); u_{j,1}= f(j\Delta x) + g(j\Delta x)\Delta t$$
(f(x)= Anfangsfunktion; g(x)=Ableitung; $r = \frac{\Delta t}{\Delta x}$)

\subsubsection{Transportgleichung}
$$u_x(x,t) + u_t(x, t) = 0; u(x,0)=P(x-t)$$
$$\frac{u(x,t+\Delta t)-u(x,t)}{\Delta t} = \frac{u(x,t) - u(x-\Delta x,
t)}{\Delta x}$$

\subsection{FVM (Finite Volumen Methode)}
$\Delta u=0$\qquad in \quad$\Omega$\\
$u(x,y)=f(x,y)$ \qquad auf \quad$\partial\Omega$\\
Der Satz von Gauss sagt: $\boxed{\oint\limits_{\Gamma}{\Delta u(x,y) dx dy}=\int\limits_{\Gamma}{\mathrm{div}~\mathrm{grad}~ u(x,y) dx dy}=\oint\limits_{\partial\Gamma}{\mathrm{grad}~ u(x,y) d\vec{n}}}$\\


Wobei der Randnormalvektor $\vec{n}$ immer senkrecht gegen das Aussengebiet $\Gamma$ gerichtet wird.\\

$\Rightarrow$ $\oint\limits_{\Gamma}{\Delta u(x,y) dx dy}=\oint\limits_{\partial\Gamma}{\mathrm{grad}~ u(x,y) d\vec{n}}=0$

\begin{minipage}{4cm}
	\includegraphics[width=4cm]{Content/Numerik/FVMPrinzip.png}
\end{minipage}
\hfill
\begin{minipage}{14cm}
	$\frac{u(P_E)-u(P_P)}{h}\cdot h+\frac{u(P_N)-u(P_P)}{h}\cdot h+\frac{u(P_W)-u(P_P)}{h}\cdot h+\frac{u(P_S)-u(P_P)}{h}\cdot h\approx 0$\\
	
	$\Rightarrow\tilde{u}(P_E)+\tilde{u}(P_N)+\tilde{u}(P_W)+\tilde{u}(P_S)+4\cdot\tilde{u}(P_P)=0$
\end{minipage}

\textbf{Vorteile:}\\
\begin{itemize}
\item Man kann mit Flussgrössen un Bilanzen rechnen, dadurch kann der Laplace-Operator $(\Delta)$ verzichtet werden und somit die aufwendige Mathematik umgangen werden.
\item Es kann mit komplizierten Geometrien gerechnet werden.  
\end{itemize}

\begin{minipage}{4cm}
	\includegraphics[width=4cm]{Content/Numerik/FVMPrinzip.png}
\end{minipage}
\hfill
\begin{minipage}{14cm}
	$\frac{u(P_E)-u(P_P)}{h}\cdot h+\frac{u(P_N)-u(P_P)}{h}\cdot h+\frac{u(P_W)-u(P_P)}{h}\cdot h+\frac{u(P_S)-u(P_P)}{h}\cdot h\approx 0$\\
	
	$\Rightarrow\tilde{u}(P_E)+\tilde{u}(P_N)+\tilde{u}(P_W)+\tilde{u}(P_S)+4\cdot\tilde{u}(P_P)=0$
\end{minipage}




\begin{minipage}{6cm}
	\includegraphics[width=6cm]{Content/Numerik/FVM1.png}
\end{minipage}
\hfill
\begin{minipage}{12cm}
\textbf{Vorgehen bei der Berechnung:}\\
\begin{enumerate}
\item Punkte $P_1,\ldots,P_n$ wählen.
\item Aufteilen des Bereichs in kleine Teilbereiche, z.B. durch Mittelsenkrechte
\item Rand diskretisieren.\\
\end{enumerate}

Für P1-Zelle:\quad $\frac{\tilde{u}(P_2)-\tilde{u}(P_1)}{\delta_{1,2}}\cdot\lambda_{1,2}+\frac{\tilde{u}(P_3)-\tilde{u}(P_1)}{\delta_{1,3}}\cdot\lambda_{1,3}+\frac{\tilde{u}(R_1)-\tilde{u}(P_1)}{\delta_1}\cdot\lambda_1$\\

Für P2-Zelle:\quad $\frac{\tilde{u}(P_1)-\tilde{u}(P_2)}{\delta_{1,2}}\cdot\lambda_{1,2}+\frac{\tilde{u}(P_3)-\tilde{u}(P_2)}{\delta_{2,3}}\cdot\lambda_{2,3}+\frac{\tilde{u}(R_2)-\tilde{u}(P_2)}{\delta_2}\cdot\lambda_2$\\

Für P3-Zelle:\quad $\frac{\tilde{u}(P_2)-\tilde{u}(P_3)}{\delta_{2,3}}\cdot\lambda_{2,3}+\frac{\tilde{u}(P_1)-\tilde{u}(P_3)}{\delta_{1,3}}\cdot\lambda_{1,3}+\frac{\tilde{u}(R_3)-\tilde{u}(P_3)}{\delta_3}\cdot\lambda_3$\\
\end{minipage}

\begin{minipage}{6cm}
	\includegraphics[width=6cm]{Content/Numerik/FVM2.png}
\end{minipage}
\hfill
\begin{minipage}{12cm}

 $\frac{\tilde{u}(P_E)-\tilde{u}(P_N)}{1/4\cdot\sqrt{2}}\cdot\frac{\sqrt{2}}{2}+\frac{\tilde{u}(P_W)-\tilde{u}(P_N)}{1/4\cdot\sqrt{2}}\cdot\frac{\sqrt{2}}{2}+\frac{\tilde{u}(P_N)-\tilde{u}(R_N)}{1/4}\cdot 1=0$\\
 
 $(\tilde{u}_E-\tilde{u}_N)\cdot 2 + (\tilde{u}_W-\tilde{u}_N)\cdot 2 + (1/2-\tilde{u}_N)\cdot 4=0$\\
 
 $0\cdot\tilde{u}_S+2\cdot\tilde{u}_E+2\cdot\tilde{u}_W-8\cdot\tilde{u}_N+2=0$
 

\end{minipage}



\input{Content/Numerik/FEM}